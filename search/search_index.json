{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SafeFeat","text":""},{"location":"api/","title":"API Reference","text":"<p>This page documents the public API of <code>safefeat</code>.</p>"},{"location":"api/#example","title":"Example","text":""},{"location":"api/#1-basic-window-features-count-sum-mean","title":"1. Basic window features (count, sum, mean)","text":"<pre><code>import pandas as pd\nfrom safefeat import build_features, WindowAgg\n\nspine = pd.DataFrame({\n    \"entity_id\": [\"u1\"],\n    \"cutoff_time\": [\"2024-01-10\"],\n})\n\nevents = pd.DataFrame({\n    \"entity_id\": [\"u1\", \"u1\", \"u1\", \"u1\"],\n    \"event_time\": [\"2024-01-05\", \"2024-01-06\", \"2023-01-01\", \"2024-01-20\"],\n    \"amount\": [10.0, 20.0, 999.0, 999.0],\n})\n\nX = build_features(\n    spine=spine,\n    tables={\"events\": events},\n    spec=[\n        WindowAgg(\n            table=\"events\",\n            windows=[\"7D\", \"30D\"],\n            metrics={\n                \"*\": [\"count\"],\n                \"amount\": [\"sum\", \"mean\"],\n            },\n        )\n    ],\n    event_time_cols={\"events\": \"event_time\"},\n)\n\nprint(X)\n\n</code></pre> <p>Expected output :</p> <pre><code>\n| entity_id | cutoff_time | events__n_events__7d | events__amount__sum__7d | events__amount__mean__7d | events__n_events__30d | events__amount__sum__30d | events__amount__mean__30d |\n| --------- | ----------- | -------------------- | ----------------------- | ------------------------ | --------------------- | ------------------------ | ------------------------- |\n| u1        | 2024-01-10  | 2                    | 30.0                    | 15.0                     | 2                     | 30.0                     | 15.0                      |\n\n</code></pre>"},{"location":"api/#build_features","title":"build_features","text":""},{"location":"api/#safefeat.core.build_features","title":"safefeat.core.build_features","text":"<pre><code>build_features(\n    spine,\n    tables,\n    spec,\n    *,\n    entity_col=\"entity_id\",\n    cutoff_col=\"cutoff_time\",\n    event_time_cols=None,\n    allowed_lag=\"0s\",\n    return_report=False,\n)\n</code></pre> <p>Build leakage-safe features from event tables.</p> <p>Parameters:</p> Name Type Description Default <code>spine</code> <code>DataFrame</code> <p>DataFrame containing entity identifiers and cutoff times.</p> required <code>tables</code> <code>dict[str, DataFrame]</code> <p>Mapping of table name to event DataFrame.</p> required <code>spec</code> <code>FeatureSpec or list[WindowAgg]</code> <p>Feature specification describing windows and aggregations.</p> required <code>entity_col</code> <code>str</code> <p>Name of entity identifier column.</p> <code>\"entity_id\"</code> <code>cutoff_col</code> <code>str</code> <p>Name of cutoff timestamp column.</p> <code>\"cutoff_time\"</code> <code>event_time_cols</code> <code>dict[str, str]</code> <p>Mapping of table name to event timestamp column.</p> <code>None</code> <code>allowed_lag</code> <code>str</code> <p>Allowed tolerance for future timestamps (pandas timedelta string).</p> <code>\"0s\"</code> <code>return_report</code> <code>bool</code> <p>If True, return a tuple <code>(features_df, AuditReport)</code> with audit information about dropped/kept event pairs.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame or (DataFrame, AuditReport)</code> <p>Feature matrix aligned to the spine. If <code>return_report</code> is True a second return value contains the audit report.</p> Source code in <code>src/safefeat/core.py</code> <pre><code>def build_features(spine, tables, spec, *, entity_col=\"entity_id\", cutoff_col=\"cutoff_time\",\n                   event_time_cols=None, allowed_lag=\"0s\", return_report=False):\n    \"\"\"Build leakage-safe features from event tables.\n\n    Parameters\n    ----------\n    spine : pandas.DataFrame\n        DataFrame containing entity identifiers and cutoff times.\n    tables : dict[str, pandas.DataFrame]\n        Mapping of table name to event DataFrame.\n    spec : FeatureSpec or list[WindowAgg]\n        Feature specification describing windows and aggregations.\n    entity_col : str, default=\"entity_id\"\n        Name of entity identifier column.\n    cutoff_col : str, default=\"cutoff_time\"\n        Name of cutoff timestamp column.\n    event_time_cols : dict[str, str]\n        Mapping of table name to event timestamp column.\n    allowed_lag : str, default=\"0s\"\n        Allowed tolerance for future timestamps (pandas timedelta string).\n    return_report : bool, default=False\n        If True, return a tuple ``(features_df, AuditReport)`` with audit\n        information about dropped/kept event pairs.\n\n    Returns\n    -------\n    pandas.DataFrame or (pandas.DataFrame, AuditReport)\n        Feature matrix aligned to the spine. If ``return_report`` is True a\n        second return value contains the audit report.\n    \"\"\"\n\n    if event_time_cols is None:\n        raise ValueError(\"event_time_cols must be provided, e.g. {'events': 'event_time'}\")\n\n    # validate spine\n    if entity_col not in spine.columns or cutoff_col not in spine.columns:\n        raise ValueError(f\"Required columns {entity_col} and/or {cutoff_col} not found in spine DataFrame\")\n\n    out = spine.copy()\n    out[cutoff_col] = pd.to_datetime(out[cutoff_col], errors=\"raise\")\n    spine_subset = out[[entity_col, cutoff_col]]\n\n    report = AuditReport() if return_report else None\n\n    if isinstance(spec, list):\n        spec = FeatureSpec(blocks=spec)\n\n    for block in spec.blocks:\n        if isinstance(block, WindowAgg): \n            events_df = tables[block.table] # get the events table specified in the block\n            event_time_col = event_time_cols[block.table] # get the event time column for this table\n\n            # Collect audit on first window; reuse for subsequent windows or report\n            audit_data_for_table = None\n\n            for w in block.windows: # for each window specified in the block\n                # get events in the window using the helper function\n                result = _events_in_window(\n                    spine=spine_subset,\n                    events=events_df,\n                    time_window=w,\n                    allowed_lag=allowed_lag,\n                    entity_col=entity_col,\n                    cutoff_col=cutoff_col,\n                    event_time_col=event_time_col,\n                    collect_audit=return_report,\n                )\n\n                if return_report:\n                    in_window, audit_data = result\n                    # Only capture audit from first window (it's the same for all windows of the same table)\n                    if audit_data_for_table is None:\n                        audit_data_for_table = audit_data\n                else:\n                    in_window = result\n\n                # process each metric in block.metrics\n                for dim, aggs in block.metrics.items():\n                    if dim != \"*\" and dim not in in_window.columns:\n                        raise ValueError(f\"Column '{dim}' not found in table '{block.table}'\")\n\n                    if dim == \"*\":\n                        # wildcard: count\n                        if \"count\" in aggs:\n                            counts = (\n                                in_window.groupby([entity_col, cutoff_col], sort=False)\n                                .size()\n                                .reset_index(name=\"count\")\n                            )\n                            feature_name = f\"{block.table}__n_events__{w.lower()}\"\n                            merged = spine_subset.merge(counts, on=[entity_col, cutoff_col], how=\"left\")\n                            out[feature_name] = merged[\"count\"].fillna(0).astype(int).values\n                    else:\n                        gb = in_window.groupby([entity_col, cutoff_col], sort=False)\n\n                        # named column aggregations\n                        if \"sum\" in aggs:\n                            sum_agg = (\n                                gb[dim]\n                                .sum()\n                                .reset_index(name=\"sum_val\")\n                            )\n                            feature_name = f\"{block.table}__{dim}__sum__{w.lower()}\"\n                            merged = spine_subset.merge(sum_agg, on=[entity_col, cutoff_col], how=\"left\")\n                            out[feature_name] = merged[\"sum_val\"].fillna(0).values\n\n                        if \"mean\" in aggs:\n                            mean_agg = (\n                                gb[dim]\n                                .mean()\n                                .reset_index(name=\"mean_val\")\n                            )\n                            feature_name = f\"{block.table}__{dim}__mean__{w.lower()}\"\n                            merged = spine_subset.merge(mean_agg, on=[entity_col, cutoff_col], how=\"left\")\n                            out[feature_name] = merged[\"mean_val\"].fillna(0).values\n                        if \"nunique\" in aggs:\n                            nunique_agg = (\n                                gb[dim]\n                                .nunique()\n                                .reset_index(name=\"nunique_val\")\n                            )\n                            feature_name = f\"{block.table}__{dim}__nunique__{w.lower()}\"\n                            merged = spine_subset.merge(nunique_agg, on=[entity_col, cutoff_col], how=\"left\")\n                            out[feature_name] = merged[\"nunique_val\"].fillna(0).astype(int).values\n\n            # Add audit data for this table if collecting reports\n            if return_report and audit_data_for_table is not None:\n                table_audit = TableAudit(\n                    table=block.table,\n                    total_joined_pairs=audit_data_for_table[\"total_joined_pairs\"],\n                    kept_pairs=audit_data_for_table[\"kept_pairs\"],\n                    dropped_future_pairs=audit_data_for_table[\"dropped_future_pairs\"],\n                    max_future_delta=audit_data_for_table[\"max_future_delta\"],\n                )\n                report.add_table(table_audit)\n\n        elif isinstance(block, RecencyBlock): # compute recency feature\n            events_df = tables[block.table]\n            event_time_col = event_time_cols[block.table]\n\n            # Filter events if a filter is specified\n            filtered_events = events_df.copy()\n            if block.filter_col is not None: \n                filtered_events = filtered_events[filtered_events[block.filter_col] == block.filter_value] \n\n            # Compute time since last event for each entity-cutoff pair\n            recency_features = _compute_recency(\n                spine=spine_subset,\n                events=filtered_events,\n                entity_col=entity_col,\n                cutoff_col=cutoff_col,\n                event_time_col=event_time_col,\n                allowed_lag=allowed_lag,\n            )\n\n            # Add recency feature column\n            feature_name = f\"{block.table}__recency\"\n            if block.filter_col is not None:\n                feature_name += f\"__{block.filter_col}_{block.filter_value}\"\n\n            merged = spine_subset.merge(recency_features, on=[entity_col, cutoff_col], how=\"left\")\n            out[feature_name] = merged[\"recency_days\"].values\n\n        else:\n            raise ValueError(f\"Unknown block type: {type(block)}\")\n\n    if return_report:\n        return out, report\n    return out\n</code></pre>"},{"location":"api/#feature-specification","title":"Feature Specification","text":""},{"location":"api/#windowagg","title":"WindowAgg","text":""},{"location":"api/#safefeat.spec.WindowAgg","title":"safefeat.spec.WindowAgg  <code>dataclass</code>","text":"<p>Specification for aggregating events within a time window.</p> <p>Attributes:</p> Name Type Description <code>table</code> <code>str</code> <p>Name of the events table to read (key in the <code>tables</code> mapping passed to :func:<code>build_features</code>).</p> <code>windows</code> <code>List[str]</code> <p>List of window lengths expressed in pandas timedelta strings (e.g. <code>\"30D\"</code>, <code>\"7D\"</code>). For each window a set of features will be produced.</p> <code>metrics</code> <code>Dict[str, List[str]]</code> <p>Mapping from a column name to a list of aggregations to compute. Use <code>\"*\"</code> as a wildcard key to request event counts (only <code>[\"count\"]</code> is supported for the wildcard). Example: <code>{\"*\": [\"count\"], \"amount\": [\"sum\", \"mean\"]}</code>.</p> Example <p>import pandas as pd from safefeat import build_features, WindowAgg</p> <p>spine = pd.DataFrame({ ...     \"entity_id\": [\"u1\"], ...     \"cutoff_time\": [\"2024-01-10\"], ... })</p> <p>events = pd.DataFrame({ ...     \"entity_id\": [\"u1\", \"u1\"], ...     \"event_time\": [\"2024-01-05\", \"2024-01-08\"], ...     \"amount\": [10, 20], ... })</p> <p>spec = [ ...     WindowAgg( ...         table=\"events\", ...         windows=[\"7D\"], ...         metrics={\"amount\": [\"sum\"], \"*\": [\"count\"]}, ...     ) ... ]</p> <p>X = build_features( ...     spine, ...     {\"events\": events}, ...     spec, ...     event_time_cols={\"events\": \"event_time\"}, ... ) X.filter(like=\"events__\").columns.tolist() ['events__amount__sum__7d', 'events__n_events__7d']</p> Source code in <code>src/safefeat/spec.py</code> <pre><code>@dataclass\nclass WindowAgg:\n    \"\"\"Specification for aggregating events within a time window.\n\n    Attributes\n    ----------\n    table:\n        Name of the events table to read (key in the `tables` mapping passed\n        to :func:`build_features`).\n    windows:\n        List of window lengths expressed in pandas timedelta strings (e.g.\n        ``\"30D\"``, ``\"7D\"``). For each window a set of features will be\n        produced.\n    metrics:\n        Mapping from a column name to a list of aggregations to compute. Use\n        ``\"*\"`` as a wildcard key to request event counts (only ``[\"count\"]``\n        is supported for the wildcard). Example: ``{\"*\": [\"count\"],\n        \"amount\": [\"sum\", \"mean\"]}``.\n\n    Example\n    -------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; from safefeat import build_features, WindowAgg\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; spine = pd.DataFrame({\n    ...     \"entity_id\": [\"u1\"],\n    ...     \"cutoff_time\": [\"2024-01-10\"],\n    ... })\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; events = pd.DataFrame({\n    ...     \"entity_id\": [\"u1\", \"u1\"],\n    ...     \"event_time\": [\"2024-01-05\", \"2024-01-08\"],\n    ...     \"amount\": [10, 20],\n    ... })\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; spec = [\n    ...     WindowAgg(\n    ...         table=\"events\",\n    ...         windows=[\"7D\"],\n    ...         metrics={\"amount\": [\"sum\"], \"*\": [\"count\"]},\n    ...     )\n    ... ]\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; X = build_features(\n    ...     spine,\n    ...     {\"events\": events},\n    ...     spec,\n    ...     event_time_cols={\"events\": \"event_time\"},\n    ... )\n    &gt;&gt;&gt; X.filter(like=\"events__\").columns.tolist()\n    ['events__amount__sum__7d', 'events__n_events__7d']\n    \"\"\"\n    table: str\n    windows: List[str]\n    metrics: Dict[str, List[str]]\n\n    def __post_init__(self):\n        # basic shape/type checks\n        if not isinstance(self.metrics, dict):\n            raise ValueError(\"metrics must be a dict\")\n\n        # allowed aggregations\n        allowed_aggs = {\"count\", \"sum\", \"mean\", \"nunique\"}\n\n        for dim, aggs in self.metrics.items():\n            # each value should be a list of strings\n            if not isinstance(aggs, list) or not all(isinstance(a, str) for a in aggs):\n                raise ValueError(f\"aggregations for '{dim}' must be a list of strings\")\n\n            if dim == \"*\":\n                # wildcard only supports a single count\n                if aggs != [\"count\"]:\n                    raise ValueError(\"'*' dimension only supports ['count']\")\n            else:\n                # ensure every aggregation is in allow list\n                for a in aggs:\n                    if a not in allowed_aggs:\n                        raise ValueError(f\"unsupported aggregation '{a}' for dimension '{dim}'\")\n</code></pre>"},{"location":"api/#recencyblock","title":"RecencyBlock","text":""},{"location":"api/#safefeat.spec.RecencyBlock","title":"safefeat.spec.RecencyBlock  <code>dataclass</code>","text":"<p>Specification for computing time since the most recent event.</p> <p>This block computes the number of days between the cutoff and the most recent matching event for each entity-cutoff pair. Optionally the block can be restricted to events that match <code>filter_col == filter_value</code>.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the events table to use.</p> required <code>filter_col</code> <code>Optional[str]</code> <p>Optional name of a column to filter on (for example <code>\"event_type\"</code>).</p> <code>None</code> <code>filter_value</code> <code>Optional[str]</code> <p>Optional value that <code>filter_col</code> must equal to be considered.</p> <code>None</code> Example <p>import pandas as pd from safefeat import build_features, RecencyBlock</p> <p>spine = pd.DataFrame({ ...     \"entity_id\": [\"u1\"], ...     \"cutoff_time\": [\"2024-01-10\"], ... })</p> <p>events = pd.DataFrame({ ...     \"entity_id\": [\"u1\"], ...     \"event_time\": [\"2024-01-08\"], ... })</p> <p>spec = [RecencyBlock(table=\"events\")]</p> <p>X = build_features( ...     spine, ...     {\"events\": events}, ...     spec, ...     event_time_cols={\"events\": \"event_time\"}, ... ) X[\"events__recency\"].iloc[0] 2</p> Source code in <code>src/safefeat/spec.py</code> <pre><code>@dataclass\nclass RecencyBlock:\n    \"\"\"Specification for computing time since the most recent event.\n\n    This block computes the number of days between the cutoff and the most\n    recent matching event for each entity-cutoff pair. Optionally the block\n    can be restricted to events that match ``filter_col == filter_value``.\n\n    Parameters\n    ----------\n    table:\n        Name of the events table to use.\n    filter_col:\n        Optional name of a column to filter on (for example ``\"event_type\"``).\n    filter_value:\n        Optional value that ``filter_col`` must equal to be considered.\n\n    Example\n    -------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; from safefeat import build_features, RecencyBlock\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; spine = pd.DataFrame({\n    ...     \"entity_id\": [\"u1\"],\n    ...     \"cutoff_time\": [\"2024-01-10\"],\n    ... })\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; events = pd.DataFrame({\n    ...     \"entity_id\": [\"u1\"],\n    ...     \"event_time\": [\"2024-01-08\"],\n    ... })\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; spec = [RecencyBlock(table=\"events\")]\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; X = build_features(\n    ...     spine,\n    ...     {\"events\": events},\n    ...     spec,\n    ...     event_time_cols={\"events\": \"event_time\"},\n    ... )\n    &gt;&gt;&gt; X[\"events__recency\"].iloc[0]\n    2\n\n    \"\"\"\n    table: str\n    filter_col: Optional[str] = None\n    filter_value: Optional[str] = None\n\n    def __post_init__(self):\n        # both filter_col and filter_value must be provided together or not at all\n        if (self.filter_col is None) != (self.filter_value is None):\n            raise ValueError(\"Both filter_col and filter_value must be provided together\")\n</code></pre>"},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#point-in-time","title":"Point-in-Time","text":"<p>The core principle of SafeFeat is point-in-time correctness: when computing features for a prediction at cutoff time $t$, only use information available before time $t$.</p> <p>Example: If you predict churn on 2024-02-15, don't use events from 2024-02-16.</p>"},{"location":"concepts/#spine","title":"Spine","text":"<p>The spine defines your prediction scenarios:</p> <pre><code>entity_id | cutoff_time\n----------|------------\nuser_1    | 2024-01-31\nuser_1    | 2024-02-15\nuser_2    | 2024-02-15\n</code></pre> <p>Each row is an \"as-of\" moment: compute features for that entity looking back from that date.</p>"},{"location":"concepts/#aggregations","title":"Aggregations","text":""},{"location":"concepts/#windowagg","title":"WindowAgg","text":"<p>Count or summarize events in a rolling time window before the cutoff.</p> <pre><code>WindowAgg(\n    table=\"events\",\n    windows=[\"7D\", \"30D\"],\n    metrics={\"*\": [\"count\"], \"amount\": [\"sum\", \"mean\"]}\n)\n</code></pre> <p>For cutoff 2024-02-15: - 7D window: 2024-02-08 to 2024-02-15 - 30D window: 2024-01-16 to 2024-02-15</p> <p>Only events falling in these windows before the cutoff are included.</p>"},{"location":"concepts/#supported-aggregations","title":"Supported Aggregations","text":"<ul> <li><code>\"count\"</code> \u2014 number of events (on wildcard <code>\"*\"</code> only)</li> <li><code>\"sum\"</code> \u2014 total of a numeric column</li> <li><code>\"mean\"</code> \u2014 average of a numeric column</li> <li><code>\"nunique\"</code> \u2014 count distinct values</li> </ul>"},{"location":"concepts/#recencyblock","title":"RecencyBlock","text":"<p>Time since the last event:</p> <pre><code>RecencyBlock(\n    table=\"events\",\n    filter_col=\"event_type\",\n    filter_value=\"purchase\"\n)\n</code></pre> <p>Returns the number of days between the cutoff and the most recent matching event.</p> <p>Useful for: - Churn modeling (days since purchase) - Fraud detection (days since login) - Activity recency</p>"},{"location":"concepts/#data-quality-leakage","title":"Data Quality &amp; Leakage","text":""},{"location":"concepts/#future-events","title":"Future Events","text":"<p>Events that occur after the cutoff are automatically excluded. This prevents leakage.</p> <pre><code>allowed_lag = \"0s\"  # Default: strict point-in-time\n# or\nallowed_lag = \"24h\"  # Allow events up to 24h after cutoff\n</code></pre> <p>Use <code>allowed_lag</code> if your event data has slight delays in ingestion.</p>"},{"location":"concepts/#audit-report","title":"Audit Report","text":"<p>The report tracks data quality by table:</p> <pre><code>features, report = build_features(..., return_report=True)\naudit = report.tables[\"events\"]\n</code></pre> <p>Available metrics: - <code>total_joined_pairs</code> \u2014 events matched to entities/cutoffs - <code>kept_pairs</code> \u2014 events within cutoff - <code>dropped_future_pairs</code> \u2014 events after cutoff (leakage risk) - <code>max_future_delta</code> \u2014 largest lateness of dropped events</p> <p>High <code>dropped_future_pairs</code> may indicate: - Ingestion delays - Timezone issues - Data quality problems</p>"},{"location":"concepts/#entity-cutoff-pairs","title":"Entity-Cutoff Pairs","text":"<p>Each row in the spine creates an entity-cutoff pair. Events are grouped by: - entity_id \u2014 which user/customer/entity - cutoff_time \u2014 the prediction moment</p> <p>When computing features, we:</p> <ol> <li>Join events to entity-cutoff pairs by entity</li> <li>Filter to events up to the cutoff time</li> <li>Aggregate by entity-cutoff pair</li> </ol> <p>Example:</p> <pre><code>Spine row: user_1, 2024-02-15\n\nJoin events for user_1:\n  2024-01-10: 10 \u2190 included\n  2024-01-20: 20 \u2190 included\n  2024-02-01: 15 \u2190 included\n  2024-02-20: 5  \u2190 excluded (after cutoff)\n\n30D window (back to 2024-01-16):\n  Count: 3\n  Sum: 45\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>Install from PyPI:</p> <pre><code>pip install safefeat\n</code></pre> <p>Install (editable, with dev tools):</p> <pre><code>pip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/#1-prepare-the-spine-and-events","title":"1. Prepare the spine and events","text":"<p>The spine defines the prediction scenarios as rows of (entity_id, cutoff_time). Events contain historical records tied to entities.</p> <pre><code>import pandas as pd\n\nspine = pd.DataFrame({\n    \"entity_id\": [\"u1\", \"u2\"],\n    \"cutoff_time\": [\"2024-01-10\", \"2024-01-31\"],\n})\n\nevents = pd.DataFrame({\n    \"entity_id\": [\"u1\", \"u1\", \"u2\", \"u2\"],\n    \"event_time\": [\"2024-01-05\", \"2024-01-06\", \"2024-01-10\", \"2024-01-30\"],\n    \"amount\": [10.0, 20.0, 5.0, 25.0],\n    \"event_type\": [\"click\", \"purchase\", \"purchase\", \"click\"],\n})\n</code></pre>"},{"location":"getting-started/#2-define-the-feature-specification","title":"2. Define the Feature Specification","text":"<p>You declare features using WindowAgg.</p> <pre><code>from safefeat import WindowAgg\n\nspec = [\n    WindowAgg(\n        table=\"events\",\n        windows=[\"7D\", \"30D\"],\n        metrics={\n            \"*\": [\"count\"],              # total events\n            \"amount\": [\"sum\", \"mean\"],   # numeric aggregations\n            \"event_type\": [\"nunique\"],   # categorical unique counts\n        },\n    )\n]\n</code></pre>"},{"location":"getting-started/#3-build-features","title":"3. Build features","text":"<pre><code>from safefeat import build_features\n\nX = build_features(\n    spine=spine,\n    tables={\"events\": events},\n    spec=spec,\n    event_time_cols={\"events\": \"event_time\"},\n    allowed_lag=\"0s\",  # prevent future leakage\n)\n\nprint(X)\n</code></pre> <p>Expected output (approximate):</p> <pre><code>| entity_id | cutoff_time | events__n_events__7d | events__amount__sum__7d | events__amount__mean__7d | events__event_type__nunique__7d | events__n_events__30d | events__amount__sum__30d | events__amount__mean__30d | events__event_type__nunique__30d |\n|-----------|------------|----------------------|--------------------------|---------------------------|----------------------------------|-----------------------|---------------------------|----------------------------|-----------------------------------|\n| u1        | 2024-01-10 | 2                    | 30.0                     | 15.0                      | 2                                | 2                     | 30.0                      | 15.0                       | 2                                 |\n| u2        | 2024-01-31 | 1                    | 25.0                     | 25.0                      | 1                                | 2                     | 30.0                      | 15.0                       | 2                                 |\n</code></pre>"},{"location":"getting-started/#how-leakage-prevention-works","title":"How Leakage Prevention Works","text":"<p>safefeat enforces:</p> <pre><code>event_time &lt;= cutoff_time\n</code></pre> <p>This guarantees that no future events are used when building features.</p> <p>If allowed_lag is set (e.g. \"5s\"), a small tolerance is allowed to handle timestamp precision issues.</p>"},{"location":"getting-started/#4-inspect-the-auditreport","title":"4. Inspect the AuditReport","text":"<p>If <code>return_report=True</code>, <code>build_features</code> returns an <code>AuditReport</code> mapping table names to <code>TableAudit</code> objects. The audit shows how many event\u2013cutoff pairs were joined, how many were kept, how many were dropped for being in the future, and the largest future delta observed.</p> <pre><code>events_audit = report.tables.get(\"events\")\nprint(\"total joined\", events_audit.total_joined_pairs)\nprint(\"kept\", events_audit.kept_pairs)\nprint(\"dropped (future)\", events_audit.dropped_future_pairs)\nprint(\"max future delta\", events_audit.max_future_delta)\n</code></pre>"},{"location":"getting-started/#advanced-recency-features","title":"Advanced: Recency Features","text":"<p>Recency features represent the time since the most recent event before each cutoff.</p> <p>Common examples: - days since last login - days since last purchase - hours since last sensor reading</p>"},{"location":"getting-started/#days-since-last-event-unfiltered","title":"Days since last event (unfiltered)","text":"<pre><code>from safefeat import build_features, RecencyBlock\n\nspec = [\n    RecencyBlock(table=\"events\")\n]\n\nX = build_features(\n    spine=spine,\n    tables={\"events\": events},\n    spec=spec,\n    event_time_cols={\"events\": \"event_time\"},\n)\n</code></pre> <p>This adds a column:  - events__recency</p>"},{"location":"getting-started/#days-since-last-event-of-a-specific-type-filtered","title":"Days since last event of a specific type (filtered)","text":"<pre><code>spec = [\n    RecencyBlock(\n        table=\"events\",\n        filter_col=\"event_type\",\n        filter_value=\"purchase\",\n    )\n]\n</code></pre> <p>This adds a column: - events__recency__event_type_purchase</p>"}]}